# Assignment 2: OpenMP, CUDA и гетерогенные вычисления

## Описание работы
Данная практическая работа посвящена изучению параллельных вычислений
на CPU и GPU, а также принципов гетерогенной параллелизации.
В рамках задания были реализованы алгоритмы с использованием OpenMP
и CUDA, а также рассмотрены теоретические аспекты распределения
вычислений между различными типами вычислительных устройств.

---

## Задача 1. Введение в гетерогенную параллелизацию (Теория)

### Что такое гетерогенная параллелизация
Гетерогенная параллелизация — это подход к вычислениям, при котором
используются различные типы вычислительных устройств (например, CPU и GPU)
одновременно. Каждый тип устройства применяется для тех задач, в которых
он наиболее эффективен.

### Различия между параллельными вычислениями на CPU и GPU
- **CPU** содержит небольшое количество мощных ядер, оптимизированных
  для последовательных и логически сложных операций.
- **GPU** содержит тысячи простых ядер, предназначенных для массовых
  параллельных вычислений с одинаковыми операциями над большими массивами данных.
- CPU лучше подходит для управления логикой программы,
  GPU — для вычислительно интенсивных задач.

### Преимущества гетерогенной параллелизации
- Более эффективное использование вычислительных ресурсов.
- Существенное ускорение обработки больших объёмов данных.
- Возможность распределения задач по их природе
  (логика — CPU, вычисления — GPU).
- Повышение общей производительности системы.

### Примеры реальных приложений
- Машинное обучение и нейронные сети.
- Обработка изображений и видео.
- Научные и инженерные вычисления.
- Финансовое моделирование.
- Компьютерная графика и игры.

---

## Задача 2. Работа с массивами и OpenMP

### Реализация
- Создание массива из 10 000 случайных чисел.
- Поиск минимального и максимального значения:
  - последовательным способом;
  - параллельно с использованием OpenMP.
- Сравнение времени выполнения двух подходов.

<p align="center">
  <img src="images/task2.png" width="100">
</p>

### Вывод
```bash
Sequential Min: 15, Max: 99997
Parallel   Min: 15, Max: 99997
Sequential time: 20 microseconds
Parallel time: 1300 microseconds
```

---

## Задача 3. Параллельная сортировка выбором с OpenMP

### Реализация
- Последовательная сортировка выбором.
- Параллельная версия с использованием OpenMP.
- Тестирование для массивов размером 1000 и 10000 элементов.

<p align="center">
  <img src="images/task3.png" width="100">
</p>


### Вывод
```bash
Array size: 1000
Sequential time: 1 ms
Parallel time: 72 ms

Array size: 10000
Sequential time: 94 ms
Parallel time: 4099 ms
```

---

## Задача 4. Сортировка на GPU с использованием CUDA

### Реализация
- Массив разбивается на подмассивы.
- Каждый подмассив сортируется отдельным блоком GPU.
- Выполняется параллельная обработка данных.
- Измеряется время выполнения ядра CUDA.

<p align="center">
  <img src="images/task4.png" width="100">
</p>


### Вывод
```bash
Array size: 1000
Sequential time: 1 ms
Parallel time:   72 ms

Array size: 10000
Sequential time: 94 ms
Parallel time:   4099 ms
```


## Контрольные вопросы к Assignment 2  

### 1. Что понимается под гетерогенной параллелизацией?
Гетерогенная параллелизация — это подход, при котором в рамках одной программы
используются различные вычислительные устройства (например, CPU и GPU),
каждое из которых применяется для выполнения наиболее подходящих ему задач.

---

### 2. В чём принципиальные различия архитектур CPU и GPU?
CPU имеет небольшое количество мощных универсальных ядер и оптимизирован
для последовательных и логически сложных операций.
GPU содержит тысячи простых ядер и предназначен для массовых
параллельных вычислений над большими массивами данных.

---

### 3. Какие типы задач лучше подходят для выполнения на GPU, а какие — на CPU?
GPU наиболее эффективен для задач с большим количеством одинаковых операций,
таких как обработка массивов, матриц, изображений и видео.
CPU лучше подходит для задач управления программой, ветвлений,
ввода-вывода и сложной логики.

---

### 4. Почему не все алгоритмы эффективно распараллеливаются с использованием OpenMP?
Многие алгоритмы содержат зависимости между данными,
критические секции и последовательные участки,
которые ограничивают степень параллелизма и снижают эффективность OpenMP.

---

### 5. В чём заключается основная идея алгоритма сортировки слиянием?
Алгоритм сортировки слиянием основан на рекурсивном делении массива
на меньшие подмассивы, их сортировке и последующем слиянии
в один отсортированный массив.

---

### 6. Какие сложности возникают при реализации сортировки слиянием на GPU?
Основные сложности связаны с синхронизацией потоков,
эффективной реализацией параллельного слияния,
а также управлением памятью на GPU.

---

### 7. Как выбор размера блока и сетки влияет на производительность вычислений на GPU?
Неправильный выбор размера блока и параметров сетки
может привести к недоиспользованию ресурсов GPU
или увеличению накладных расходов,
что негативно сказывается на производительности.

---

### 8. Почему гетерогенный подход может быть эффективнее использования только CPU или только GPU?
Гетерогенный подход позволяет распределять задачи между CPU и GPU
в соответствии с их архитектурными особенностями,
что обеспечивает более эффективное использование ресурсов
и повышение общей производительности системы.
